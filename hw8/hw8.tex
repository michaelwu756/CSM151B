\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{tikz}
\begin{document}
\title{Computer Science M151B, Homework 8}
\date{May 30th, 2018}
\author{Michael Wu\\UID: 404751542}
\maketitle

\section*{Problem 1}

The average number of cycles that a memory access will take is
\[0.94\times 1\text{ cycles} + 0.06\times 55\text{ cycles} = 4.24 \text{ cycles}\]
Each cycle takes \(0.5\) ns, which means that the effective access time is
\[2.12\times 10^{-9} \text{ s}\]

\section*{Problem 2}

The number of sets in the cache would decrease to 128, which would require 7 index bits and 23 tag bits.
Each cache entry has 1 valid bit, 23 tag bits, and 32 data bits, which is 56 bits total. There are \(128\times 8=1024\)
cache entries total which means that the bits of storage required to implement the cache is 57344 bits.

\section*{Problem 3}

In a fully associative cache, there would be no index which leaves us with 15 bits of block offset. Thus the block size at the maximum could
be 32768 words. In a direct-mapped cache, there would be 11 index bits which leaves 4 bits of block offset. Thus the block size at a minimum
could be 16 words.

\section*{Problem 4}

The cache information is shown below. Note that since these are 32-bit addresses, both the binary address and the tag would be
extended by an additional 24 bits that are entirely zero. I have left them out for readability.
\begin{center}
        \begin{tabular}{c|c|c|c|c}
                Word Address & Binary Address & Tag & Index & Hit/Miss\\
                \hline
                3 & 00000011 & 0000 & 001 & Miss\\
                180 & 10110100 & 1011 & 010 & Miss\\
                43 & 00101011 & 0010 & 101 & Miss\\
                2 & 00000010 & 0000 & 001 & Hit\\
                191 & 10111111 & 1011 & 111 & Miss\\
                88 & 01011000 & 0101 & 100 & Miss\\
                190 & 10111110 & 1011 & 111 & Hit\\
                14 & 00001110 & 0000 & 111 & Miss\\
                181 & 10110101 & 1011 & 010 & Hit\\
                44 & 00101100 & 0010 & 110 & Miss\\
                186 & 10111010 & 1011 & 101 & Miss\\
                253 & 11111101 & 1111 & 110 & Miss
        \end{tabular}
\end{center}
The final cache contents are shown below.
\begin{center}
        \begin{tabular}{c|c|c}
                Block Number & Word Addresses & Tag \\
                \hline
                1 & 2-3 & 0000 \\
                2 & 180-181 & 1011 \\
                4 & 88-89 & 0101 \\
                5 & 186-187 & 1011 \\
                6 & 252-253 & 1111 \\
                7 & 14-15 & 0000
        \end{tabular}
\end{center}

\section*{Problem 5}

Assuming the cache is byte addressable, one miss will occur for every 16 accesses. Thus the miss rate is 6.25\%.
The miss rate does not depend on the working set size, since no memory location is referenced more than once. So replacing
block frames is not the reason for our misses, and we do not need to hold the working set in memory. The miss rate can
vary with the size of the cache, but only if the cache size changes due to changing the block size. Adding or removing
block frames will not change the miss rate. Increasing the block size will reduce the miss rate, as more accesses can occur
before the program moves onto the next block of memory. The types of misses that occur in this program are compulsory misses.

\section*{Problem 6}

The miss rate with a 16 byte block size will be 12.5\%, the miss rate with a 64 byte block size will be 3.125\%, and the miss rate with a
128 byte block size will be 1.5625\%. The workload is exploiting spacial locality.

\section*{Problem 7}

Since only the first access will be a miss and the working set size is 524288 bytes, one out of 524288 accesses will be a miss. Thus the
miss rate will be 0.000190735\%.

\section*{Problem 8}

\paragraph{a)}

\paragraph{b)}

\section*{Problem 9}

\paragraph{a)}

\paragraph{b)}

\end{document}